<!doctype html>
<html lang="en">
<head>
<title>Image Colorization</title>
<meta property="og:title" content=DDColor" />
<meta name="twitter:title" content="Your Project Name" />
<meta name="description" content="Your project about your cool topic described right here." />
<meta property="og:description" content="Your project about your cool topic described right here." />
<meta name="twitter:description" content="Your project about your cool topic described right here." />
<meta property="og:type" content="website" />
<meta name="twitter:card" content="summary" /> 
<meta name="viewport" content="width=device-width,initial-scale=1" />
<!-- bootstrap for mobile-friendly layout -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css" integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">
<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js" integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj" crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.bundle.min.js" integrity="sha384-Fy6S3B9q64WdZWQUiU+q4/2Lc9npb8tCaSX9FK7E8HnRr0Jz8D6OP9dO5Vg3Q9ct" crossorigin="anonymous"></script>
<link href="https://fonts.googleapis.com/css?family=Open+Sans:300,400,700" rel="stylesheet">
<link href="style.css" rel="stylesheet">

</head>
<body class="nd-docs">
<div class="nd-pageheader">
 <div class="container">
 <h1 class="lead">
 <nobr class="widenobr">DD Color</nobr>
 <nobr class="widenobr">For DS4440</nobr>
 </h1>
 </div>
</div><!-- end nd-pageheader -->

<div class="container">
<div class="row">
<div class="col justify-content-center text-center">
<h2>An Analysis of DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders</h2>

</div>
</div>
<div class="row">
<div class="col">

<section id="introduction"> <h1>1. Introduction</h1> <p>The goal of this project is to investigate the potential of turning the DDColor method, proposed by Kang et al. in their paper "DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders," into a practical product for image colorization. Specifically, we aim to explore the following two main questions:</p> <p><strong>1. Can the DDColor method be effectively applied to new, diverse datasets beyond the benchmarks used in the original paper?</strong></p> <p>While the authors demonstrated the superior performance of DDColor on datasets like ImageNet, COCO-Stuff, and ADE20K, it is essential to evaluate the method's generalization capability across a broader range of image domains and scenarios. By testing DDColor on new datasets, we can assess its robustness and identify potential limitations or areas for improvement.</p> <p><strong>2. Is it possible to achieve comparable performance with a reduced training data requirement?</strong></p> <p>Training deep learning models often demands large-scale datasets, which can be challenging to obtain, especially in specialized domains. In this project, we will investigate whether the DDColor method can be fine-tuned or adapted to achieve satisfactory results with a smaller training dataset, potentially making it more accessible and resource-efficient for real-world applications.</p> <p>Through this project, we aim to gain insights into the practical applicability of the DDColor method and explore potential avenues for enhancing its performance, efficiency, and scalability. By addressing these questions, we hope to contribute to the development of effective and accessible image colorization solutions that can benefit various industries and applications.</p> </section>

<section id="review"> <h1>2. Review of DDColor Paper</h1> <p>The paper "DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders" by Kang et al. presents a novel end-to-end method for automatic image colorization called DDColor. The main novelty of DDColor lies in its dual decoder architecture, consisting of a pixel decoder and a color decoder.</p></p> <p> <img src="architecture.png" alt="DDColor Architecture" class="img-fluid"> <br> </p> <p></p> <p>DDColor represents a significant advancement in automatic image colorization by learning color representations in an end-to-end manner without relying on manually designed priors. The model exhibits good generalization ability and can handle diverse objects and contexts, making it a promising solution for real-world applications such as legacy photo restoration, video remastering, and art creation.</p> <p>The pixel decoder restores the spatial resolution of the image by gradually upsampling the features extracted from the encoder. Crucially, the color decoder learns semantic-aware color queries from multi-scale visual features, eliminating the need for hand-crafted priors used in previous methods. The color decoder utilizes a query-based transformer to establish correlations between color representations and multi-scale semantic representations via cross-attention, effectively alleviating color bleeding issues prevalent in existing approaches.</p> <p>Additionally, the authors introduce a simple yet effective colorfulness loss to enhance the color richness of the generated results. Through extensive experiments on public benchmarks like ImageNet, COCO-Stuff, and ADE20K, the authors demonstrate that DDColor achieves superior performance over state-of-the-art methods, both quantitatively (in terms of metrics like FID and colorfulness scores) and qualitatively (producing more natural, vivid, and semantically consistent colorization results, even for complex scenes).</p></section>

<section id="implementation">
 <h1>3. Implementation</h1>
 <h3>Encoder</h3>
 <h3>Pixel Decoder</h3>
 <h3>Color Decoder</h3>
 <h3>Fusion Module</h3>
 <h3>Loss Functions</h3>
 <h4>PixelLoss</h4>
 <h4>PerceptualLoss</h4>
 <h4>AdversarialLoss</h4>
 <h4>ColorfulnessLoss</h4>
</section>

<section id="findings">
 <h1>4. Experimental Findings</h1>
 <p>Our experiments yielded the following results:</p>
<table>
  <tr>
    <th>Checkpoint&nbsp;</th>
    <th>Average&nbsp;FID&nbsp;&#177;&nbsp;0.001</th>
    <th>Average&nbsp;Colorfulness&nbsp;Score&nbsp;&#177;&nbsp;0.001</th>
    <th>Average&nbsp;PSNR&nbsp;&#177;&nbsp;0.001</th>
  </tr>
  <tr>
    <td>1</td>
    <td>8.359</td>
    <td>0.003</td>
    <td>40.078</td>
  </tr>
  <tr>
    <td>2</td>
    <td>28.422</td>
    <td>0.006</td>
    <td>36.257</td>
  </tr>
  <tr>
    <td>3</td>
    <td>11.320</td>
    <td>0.003</td>
    <td>45.376</td>
  </tr>
  <tr>
    <td>4</td>
    <td>10.304</td>
    <td>0.003</td>
    <td>44.706</td>
  </tr>
  <tr>
    <td>5</td>
    <td>9.084</td>
    <td>0.001</td>
    <td>41.716</td>
  </tr>
  <tr>
    <td>6</td>
    <td>5.206</td>
    <td>0.001</td>
    <td>46.669</td>
  </tr>
  <tr>
    <td>7</td>
    <td>7.737</td>
    <td>0.002</td>
    <td>41.932</td>
  </tr>
  <tr>
    <td>8</td>
    <td>8.711</td>
    <td>0.003</td>
    <td>44.707</td>
  </tr>
</table>
</section>

<section id="conclusion">
  <h1>5. Conclusion</h1>
  <p>Conclusion content goes here...</p>
</section>

<h2>Literature Review; Biography; Social Impact; Industry Applications; Follow-on Research; and Peer-Review</h2>

<p>Just as we have done in the role-playing exercise, analyze the paper from all perspectives.
</p>

<p>Optionally, in addition to a reading-based analysis, implement the ideas of the paper in code, and report on your findings.
</p>

<h3>References</h3>

<p><a name="kang2023ddcolor">[1]</a> <a href="https://arxiv.org/abs/2212.11613"
  >Xiaoyang Kang, Tao Yang, Wenqi Ouyang, Peiran Ren, Lingzhi Li, Xuansong Xie.
  <em>DDColor: Towards Photo-Realistic Image Colorization via Dual Decoders.</em></a>
  arXiv preprint arXiv:2212.11613, 2023.
</p>



<h2>Team Members</h2>
                                                   
<p>Hamza Tahboub, Andrew Stelmach</p>

  
</div><!--col-->
</div><!--row -->
</div> <!-- container -->

<footer class="nd-pagefooter">
  <div class="row">
    <div class="col-6 col-md text-center">
      <a href="https://cs7150.baulab.info/">About CS 7150</a>
    </div>
  </div>
</footer>

</body>
<script>
$(document).on('click', '.clickselect', function(ev) {
  var range = document.createRange();
  range.selectNodeContents(this);
  var sel = window.getSelection();
  sel.removeAllRanges();
  sel.addRange(range);
});
// Google analytics below.
window.dataLayer = window.dataLayer || [];
</script>
</html>
